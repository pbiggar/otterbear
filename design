Vague design plans:

At least 5 implementations:

 - tracer
 - methodjit
 - type-inference/other analysis
 - interpreter
 - ahead-of-time compiler
   - heavy optimization

On the side:
  - good GC from its first implementation
  - assembler based on LLVM (generate bitcode?)
    - why not nitro? well, why nitro
  - ropes
  - ICs
  - fatvals
  - shape/map optimization
  - register allocation

All of these should be based probably on two IRs:
  - a register-based high-level bytecode (BC)
    - compiler should be written in a static subset of this
  - a low-level assemblable IR (LIR)
    - probably virtual registers

The aim is to never reimplement the same thing twice!

Pypy creates a translation from bytecode to LIR, and bases its implementations on top of that.


So the rough order of implementations is ('-' is TODO, '+' is done)

  + define a bytecode for:
    + functions
    + addition
    + copying
    + integer operations

  + write the interpreter for it
  - write the ahead-of-time compiler
    - this comes early because we need to understand the constraints for how we
      write everything else
    - rewrite interpreter using this
      - figure out how Pypy does this

  - expand the language
    - strings, objects

  - write the GC
  - write tracer for it

  - expand the language
    - ffi

  - make fatvals work

  - expand the language:
    - actually parse javascript
    - 

  - write ropes
  - write the type-inference


